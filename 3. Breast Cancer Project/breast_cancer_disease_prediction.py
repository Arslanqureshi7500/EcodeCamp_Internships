# -*- coding: utf-8 -*-
"""3. Project of Breast Cancer Disease Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16_yVCLTPlPmPNFcHHoTceBt7-uCKyaen

## ***Importing the Dependencies***
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets as datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

"""# **Data Collection and Processing**"""

# Loading the data from sklearn
data = datasets.load_breast_cancer()

print(data)

# loading the data to a panda dataframe
data_frame = pd.DataFrame(data.data, columns = data.feature_names)

data_frame.head()

# Heatmap for visualizing correlations between features
plt.figure(figsize=(12, 10))
sns.heatmap(data_frame.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

# Boxplots for visualizing distribution of features
plt.figure(figsize=(15, 10))
data_frame.boxplot()
plt.title("Boxplots of Features")
plt.xticks(rotation=90)
plt.show()

# Histograms for visualizing distribution of features
data_frame.hist(bins=30, figsize=(20, 20))
plt.title("Histograms of Features")
plt.show()

# adding the target 'column to the data frame'
data_frame['label'] = data.target

#print lasat five rows of the dataframe
data_frame.tail()

# Basic Analysis and processing
# number of rows and columns in the dataset
data_frame.shape

# to check missing / null values
data_frame.isnull().sum()

# Missing Data Heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(data_frame.isnull(), cbar=False, cmap='viridis')
plt.title("Missing Data Heatmap")
plt.show()

# statistical measures about the data
data_frame.describe()

# Plotting statistical measures
data_frame.describe().plot(kind='bar', figsize=(15, 10))
plt.title("Statistical Measures of Features")
plt.xticks(rotation=90)
plt.ylabel("Value")
plt.show()

# checking the distribution of target variable
data_frame['label'].value_counts()

"""1 --> Benign

0 --> Malignant
"""

data_frame.groupby('label').mean()

"""## **Seprate the features for Input and target**"""

# split the data for fitting machine learning
X = data_frame.drop(columns = 'label', axis = 1)
Y = data_frame['label']

print(X)

print(Y)

"""# **Splitting the data into training data & Testing data**"""

# split the data for training and testing
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)

print(X.shape, X_train.shape, X_test.shape)

print(Y.shape, Y_train.shape, Y_test.shape)

"""# **Model Training**
## **Logistic Regression**
"""

model = LogisticRegression()

# training the logistic regression model using training data
model.fit(X_train, Y_train)

"""## **Model Evaluation of Logistic Regression**
### **Accuracy Score**
"""

# accuracy on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)

print("The Training Accuracy score is: ", round(training_data_accuracy * 100, 2), "%")

# accuracy on testing data
X_test_prediction = model.predict(X_test)
testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)

print("The Testing Accuracy score is: ", round(testing_data_accuracy * 100, 2), "%")

# Assuming you have X_test_prediction and Y_test from your logistic regression model

# Create a scatter plot of the actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, X_test_prediction)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Logistic Regression Model Evaluation")
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=2)  # Add a diagonal line for perfect prediction
plt.show()

"""# **Building Predective System of According to Logistic Regression**"""

# Get the row at index 1
input_data = data_frame.iloc[-1, :-1]
# input_data = (13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The Breast cancer is Malignant')

else:
  print('The Breast Cancer is Benign')

# Assuming you have 'input_data_reshaped' and 'prediction' from your previous code

# Create a bar chart showing the predicted class probability
plt.figure(figsize=(6, 4))
plt.bar(['Benign', 'Malignant'], [1 if prediction[0] == 1 else 0, 1 if prediction[0] == 0 else 0])
plt.title('Predicted Class Probability')
plt.xlabel('Class')
plt.ylabel('Probability')
plt.show()

"""# **2. Model Training - Decision Tree**"""

# # **Model Training - Decision Tree**
model_dt = DecisionTreeClassifier()

# Training the Decision Tree model using training data
model_dt.fit(X_train, Y_train)

"""## **Model Evaluation of Decision Tree**
#### **Accuracy Score**
"""

# # accuracy on training data
X_train_prediction_dt = model_dt.predict(X_train)
training_data_accuracy_dt = accuracy_score(Y_train, X_train_prediction_dt)

print("The Training Accuracy score for Decision Tree is: ", round(training_data_accuracy_dt * 100, 2), "%")

# accuracy on testing data
X_test_prediction_dt = model_dt.predict(X_test)
testing_data_accuracy_dt = accuracy_score(Y_test, X_test_prediction_dt)

print("The Testing Accuracy score for Decision Tree is: ", round(testing_data_accuracy_dt * 100, 2), "%")

# Assuming you have X_test_prediction_dt and Y_test from your decision tree model

# Create a scatter plot of the actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, X_test_prediction_dt)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Decision Tree Model Evaluation")
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=2)  # Add a diagonal line for perfect prediction
plt.show()

"""## **Building Predective System - Decision Tree**

"""

input_data = data_frame.iloc[-1, :-1]

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction_dt = model_dt.predict(input_data_reshaped)
print(prediction_dt)

if (prediction_dt[0] == 0):
  print('The Breast cancer is Malignant (According to Decision Tree)')

else:
  print('The Breast Cancer is Benign (According to Decision Tree)')

# Assuming you have 'input_data_reshaped' and 'prediction_dt' from your previous code

# Create a bar chart showing the predicted class probability for Decision Tree
plt.figure(figsize=(6, 4))
plt.bar(['Benign', 'Malignant'], [1 if prediction_dt[0] == 1 else 0, 1 if prediction_dt[0] == 0 else 0])
plt.title('Predicted Class Probability (Decision Tree)')
plt.xlabel('Class')
plt.ylabel('Probability')
plt.show()

"""# **3. Model Training - SVM**
# **Model Training - SVM**
"""

model_svm = SVC(kernel='linear')  # You can try different kernels like 'rbf', 'poly'

# Training the SVM model using training data
model_svm.fit(X_train, Y_train)

"""# **Model Evaluation of SVM**
## **Accuracy Score**
"""

# # accuracy on training data
X_train_prediction_svm = model_svm.predict(X_train)
training_data_accuracy_svm = accuracy_score(Y_train, X_train_prediction_svm)

print("The Training Accuracy score for SVM is: ", round(training_data_accuracy_svm * 100, 2), "%")

# accuracy on testing data
X_test_prediction_svm = model_svm.predict(X_test)
testing_data_accuracy_svm = accuracy_score(Y_test, X_test_prediction_svm)

print("The Testing Accuracy score for SVM is: ", round(testing_data_accuracy_svm * 100, 2), "%")

# Assuming you have X_test_prediction_svm and Y_test from your SVM model

# Create a scatter plot of the actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, X_test_prediction_svm)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("SVM Model Evaluation")
plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=2)  # Add a diagonal line for perfect prediction
plt.show()

"""# **Building Predective System - SVM**"""

input_data = data_frame.iloc[-1, :-1]

# change the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array as we are predicting for one datapoint
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction_svm = model_svm.predict(input_data_reshaped)
print(prediction_svm)

if (prediction_svm[0] == 0):
  print('The Breast cancer is Malignant (According to SVM)')

else:
  print('The Breast Cancer is Benign (According to SVM)')

# Assuming you have 'input_data_reshaped' and 'prediction_svm' from your previous code

# Create a bar chart showing the predicted class probability for SVM
plt.figure(figsize=(6, 4))
plt.bar(['Benign', 'Malignant'], [1 if prediction_svm[0] == 1 else 0, 1 if prediction_svm[0] == 0 else 0])
plt.title('Predicted Class Probability (SVM)')
plt.xlabel('Class')
plt.ylabel('Probability')
plt.show()

"""# **Evaluate model performance and select the best one**"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# Function to evaluate model performance
def evaluate_model(model, X_test, Y_test):
  Y_pred = model.predict(X_test)
  accuracy = accuracy_score(Y_test, Y_pred)
  precision = precision_score(Y_test, Y_pred)
  recall = recall_score(Y_test, Y_pred)
  f1 = f1_score(Y_test, Y_pred)
  roc_auc = roc_auc_score(Y_test, Y_pred)
  conf_matrix = confusion_matrix(Y_test, Y_pred)

  print("Accuracy:", accuracy)
  print("Precision:", precision)
  print("Recall:", recall)
  print("F1-score:", f1)
  print("ROC AUC:", roc_auc)
  print("Confusion Matrix:\n", conf_matrix)

  return accuracy, precision, recall, f1, roc_auc


# Evaluate Logistic Regression
print("Logistic Regression:")
lr_metrics = evaluate_model(model, X_test, Y_test)


# Evaluate Decision Tree
print("\nDecision Tree:")
dt_metrics = evaluate_model(model_dt, X_test, Y_test)


# Evaluate SVM
print("\nSVM:")
svm_metrics = evaluate_model(model_svm, X_test, Y_test)


# Compare model performance (e.g., based on accuracy)
model_names = ["Logistic Regression", "Decision Tree", "SVM"]
accuracies = [lr_metrics[0], dt_metrics[0], svm_metrics[0]]

plt.figure(figsize=(8, 6))
plt.bar(model_names, accuracies)
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Performance Comparison")
plt.show()

# Select the best model based on your chosen metric (e.g., accuracy)
best_model_index = np.argmax(accuracies)
best_model_name = model_names[best_model_index]
print("\nThe best performing model is:", best_model_name)

